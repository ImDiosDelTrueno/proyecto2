{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "794dJxsVy3C7"
      },
      "outputs": [],
      "source": [
        "#Proyecto 2 de Gómez Guzmán Luis Enrique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, cross_val_score, GridSearchCV)\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        "    roc_curve,\n",
        "    roc_auc_score\n",
        ")\n",
        "import os\n",
        "\n",
        "class DataLoadError(Exception):\n",
        "    \"\"\"Excepción para errores de carga de datos.\"\"\"\n",
        "\n",
        "    def __init__(self, mensaje = \"Error al cargar los datos\"):\n",
        "        self.mensaje = mensaje\n",
        "        super().__init__(self.mensaje)\n",
        "\n",
        "class ModelTrainingError(Exception):\n",
        "    \"\"\"Excepción para errores\n",
        "    durante el entrenamiento de modelos.\"\"\"\n",
        "\n",
        "    def __init__(self, mensaje = \"Error durante el entrenamiento del modelo\"):\n",
        "        self.mensaje = mensaje\n",
        "        super().__init__(self.mensaje)\n",
        "\n",
        "class Clasificadores():\n",
        "    \"\"\"\n",
        "    Clase para gestionar los clasificadores.\n",
        "    Se implementan diversos métodos de clasificación comparatia\n",
        "    \"\"\"\n",
        "    def __init__(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Inicializa los clasificadors con datos de entrenamiento.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "\n",
        "        self.X_train = X_train_scaled\n",
        "        self.y_train = y_train\n",
        "\n",
        "        # Inicializar clasificadores con búsqueda de hiperparámetros\n",
        "\n",
        "        self.modelos = {\n",
        "            'Regresión Logística': {\n",
        "                'modelo': LogisticRegression(random_state = 42),\n",
        "                'params': {\n",
        "                    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                    'penalty': ['l1', 'l2'],\n",
        "                    'solver': ['liblinear']\n",
        "                }\n",
        "            },\n",
        "            'KNN': {\n",
        "                'modelo': KNeighborsClassifier(),\n",
        "                'params': {\n",
        "                    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "                    'weights': ['uniform', 'distance'],\n",
        "                    'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
        "                }\n",
        "            },\n",
        "            'SVM': {\n",
        "                'modelo': SVC(probability = True, random_state = 42),\n",
        "                'params': {\n",
        "                    'C': [0.1, 1, 10, 100],\n",
        "                    'kernel': ['linear', 'rbf', 'poly'],\n",
        "                    'gamma': ['scale', 'auto']\n",
        "                }\n",
        "            },\n",
        "            'Árbol de Decisión': {\n",
        "                'modelo': DecisionTreeClassifier(random_state = 42),\n",
        "                'params': {\n",
        "                    'max_depth': [3, 5, 7, 10],\n",
        "                    'min_samples_split': [2, 5, 10],\n",
        "                    'criterion': ['gini', 'entropy']\n",
        "                }\n",
        "            },\n",
        "            'Random Forest': {\n",
        "                'modelo': RandomForestClassifier(random_state = 42),\n",
        "                'params': {\n",
        "                    'n_estimators': [50, 100, 200],\n",
        "                    'max_depth': [3, 5, 7, 10],\n",
        "                    'min_samples_split': [2, 5, 10]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.resultados = {}\n",
        "        self.mejores_modelos = {}\n",
        "\n",
        "    def entrenar_modelos(self):\n",
        "        \"\"\"\n",
        "        Entrena los modelos con búsqueda de hiperparámetros.\n",
        "\n",
        "        \"\"\"\n",
        "        try:\n",
        "            for nombre, config in self.modelos.items():\n",
        "\n",
        "                # Realizar búsqueda de cuadrícula de hiperparámetros\n",
        "\n",
        "                grid_search = GridSearchCV(\n",
        "                    estimator = config['modelo'],\n",
        "                    param_grid = config['params'],\n",
        "                    cv = 5,\n",
        "                    scoring = 'accuracy',\n",
        "                    n_jobs = -1\n",
        "                )\n",
        "\n",
        "                # Ajustar el modelo con búsqueda de hiperparámetros\n",
        "\n",
        "                grid_search.fit(self.X_train, self.y_train)\n",
        "\n",
        "                # Guardar el mejor modelo\n",
        "\n",
        "                self.mejores_modelos[nombre] = grid_search.best_estimator_\n",
        "                print(f\"\\nMejores parámetros para {nombre}:\")\n",
        "                print(grid_search.best_params_)\n",
        "        except Exception as e:\n",
        "            raise ModelTrainingError(f\"Error entrenando modelos: {str(e)}\")\n",
        "\n",
        "    def evaluar_modelos(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evalúa el rendimiento de los modelos.\n",
        "\n",
        "        \"\"\"\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        for nombre, modelo in self.mejores_modelos.items():\n",
        "            y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "            # Métricas adicionales\n",
        "\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                y_test, y_pred, average = 'weighted'\n",
        "            )\n",
        "\n",
        "            # Calcular curva ROC\n",
        "\n",
        "            y_pred_proba = modelo.predict_proba(X_test_scaled)[:, 1]\n",
        "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "            self.resultados[nombre] = {\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'matriz_confusion': confusion_matrix(y_test, y_pred),\n",
        "                'reporte_clasificacion': classification_report(y_test, y_pred),\n",
        "                'fpr': fpr,\n",
        "                'tpr': tpr,\n",
        "                'roc_auc': roc_auc\n",
        "            }\n",
        "\n",
        "    def validacion_cruzada(self, X, y, cv = 5):\n",
        "        \"\"\"\n",
        "        Realiza validación cruzada para cada modelo.\n",
        "\n",
        "        \"\"\"\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        print(\"\\n--- VALIDACIÓN CRUZADA ---\")\n",
        "        for nombre, modelo in self.mejores_modelos.items():\n",
        "\n",
        "            scores = cross_val_score(modelo, X_scaled, y, cv = cv,\n",
        "                                     scoring = 'accuracy')\n",
        "\n",
        "            print(f\"\\n{nombre}:\")\n",
        "            print(f\"Precisión (CV):{scores.mean():.2%} \\\n",
        "            (+/- {scores.std() * 2:.2%}))\")\n",
        "\n",
        "    def visualizar_resultados(self):\n",
        "        \"\"\"\n",
        "        Genera visualizaciones comparativas de los modelos.\n",
        "\n",
        "        \"\"\"\n",
        "        # Crear directorio para guardar gráficas si no existe\n",
        "\n",
        "        os.makedirs('graficas', exist_ok = True)\n",
        "\n",
        "        # Grafica de precision\n",
        "\n",
        "        plt.figure(figsize = (12, 6))\n",
        "        accuracies = [res['accuracy'] for res in self.resultados.values()]\n",
        "        nombres = list(self.resultados.keys())\n",
        "\n",
        "        bars = plt.bar(nombres, accuracies)\n",
        "        plt.title('Precisión de Modelos de Clasificación', fontsize = 15)\n",
        "        plt.xlabel('Modelo', fontsize = 12)\n",
        "        plt.ylabel('Accuracy', fontsize = 12)\n",
        "        plt.xticks(rotation = 45)\n",
        "\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                     f'{height:.2%}',\n",
        "                     ha = 'center', va = 'bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('graficas/comparacion_accuracies.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Curvas ROC\n",
        "\n",
        "        plt.figure(figsize = (10, 8))\n",
        "        for nombre, resultado in self.resultados.items():\n",
        "            plt.plot(\n",
        "                resultado['fpr'],\n",
        "                resultado['tpr'],\n",
        "                label = f'{nombre} (AUC = {resultado[\"roc_auc\"]:.2f})'\n",
        "            )\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--', label = 'Línea base')\n",
        "        plt.title('Curvas ROC de Clasificadores', fontsize = 15)\n",
        "        plt.xlabel('Tasa de Falsos Positivos', fontsize = 12)\n",
        "        plt.ylabel('Tasa de Verdaderos Positivos', fontsize = 12)\n",
        "        plt.legend(loc = 'lower right')\n",
        "        plt.savefig('graficas/curvas_roc.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Matrices de confusion\n",
        "\n",
        "        for nombre, resultado in self.resultados.items():\n",
        "            plt.figure(figsize = (8, 6))\n",
        "            sns.heatmap(\n",
        "                resultado['matriz_confusion'],\n",
        "                annot = True,\n",
        "                fmt = 'd',\n",
        "                cmap = 'Blues'\n",
        "            )\n",
        "            plt.title(f'Matriz de Confusión - {nombre}')\n",
        "            plt.xlabel('Predicción')\n",
        "            plt.ylabel('Real')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'graficas/matriz_confusion_{nombre}.png')\n",
        "            plt.close()\n",
        "\n",
        "        #Impreson dr  resultadis\n",
        "\n",
        "        print(\"\\n--- COMPARACIÓN DE MODELOS ---\")\n",
        "        for nombre, resultado in self.resultados.items():\n",
        "            print(f\"\\n{nombre}:\")\n",
        "            print(f\"Accuracy: {resultado['accuracy']:.2%}\")\n",
        "            print(f\"F1 Score: {resultado['f1_score']:.2%}\")\n",
        "            print(f\"Precisión: {resultado['precision']:.2%}\")\n",
        "            print(f\"Recall: {resultado['recall']:.2%}\")\n",
        "            print(f\"AUC-ROC: {resultado['roc_auc']:.2f}\")\n",
        "            print(\"\\nReporte de Clasificación:\")\n",
        "            print(resultado['reporte_clasificacion'])\n",
        "\n",
        "def preparar_datos(ruta_archivo):\n",
        "    \"\"\"\n",
        "    Prepara los datos para clasificación.\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Cargar datos desde CSV\n",
        "\n",
        "        datos = pd.read_csv('/content/drive/MyDrive/cancer.csv')\n",
        "\n",
        "        # Información del dataset\n",
        "\n",
        "        print(\"Información del Dataset:\")\n",
        "        print(datos.info())\n",
        "\n",
        "\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        # Identificar columna objetivo\n",
        "\n",
        "        if 'diagnosis' in datos.columns:\n",
        "            y = le.fit_transform(datos['diagnosis'])\n",
        "            X = datos.select_dtypes \\\n",
        "             (include=[np.number]).drop(columns=['diagnosis'])\n",
        "        else:\n",
        "            # Usar primera columna categórica como etiqueta\n",
        "\n",
        "            columna_objetivo = datos.select_dtypes \\\n",
        "             (include = ['object']).columns[0]\n",
        "            y = le.fit_transform(datos[columna_objetivo])\n",
        "            X = datos.select_dtypes \\\n",
        "             (include = [np.number]).drop(columns = [columna_objetivo])\n",
        "\n",
        "        # Eliminar columnas con alta correlación\n",
        "\n",
        "        corr_matrix = X.corr().abs()\n",
        "        upper_tri = corr_matrix.where \\\n",
        "         (np.triu(np.ones(corr_matrix.shape), k = 1).astype(bool))\n",
        "        to_drop = [column for column in upper_tri.columns if \\\n",
        "                   any(upper_tri[column] > 0.95)]\n",
        "        X = X.drop(columns = to_drop)\n",
        "\n",
        "        X, y = preparar_datos('/content/drive/MyDrive/cancer.csv')\n",
        "        return X, y\n",
        "\n",
        "    except Exception as e:\n",
        "        raise DataLoadError(f\"Error preparando datos: {e}\")\n",
        "\n",
        "# Implementacion del metodo main\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Función principal que ejecuta el proyecto de clasificación.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Intentar cargar datos de diferentes rutas posibles\n",
        "\n",
        "        rutas_drive = [\n",
        "            'cancer.csv',\n",
        "            './cancer.csv',\n",
        "            '../cancer.csv',\n",
        "            './data/cancer.csv',\n",
        "            '/content/cancer.csv',\n",
        "            '/content/drive/MyDrive/cancer.csv',\n",
        "        ]\n",
        "\n",
        "        ruta_archivo = '/content/drive/MyDrive/cancer.csv'\n",
        "\n",
        "        for ruta in rutas_drive:\n",
        "            try:\n",
        "                if os.path.exists(ruta):\n",
        "                    ruta_archivo = ruta\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if not ruta_archivo:\n",
        "            raise FileNotFoundError(\"No se encontró el archivo cancer.csv\")\n",
        "\n",
        "        # Preparar datos\n",
        "\n",
        "        ruta_archivo = '/content/drive/MyDrive/cancer.csv'\n",
        "        X, y = preparar_datos(ruta_archivo)\n",
        "\n",
        "        # Información sobre distribución de clases\n",
        "\n",
        "        print(\"\\nDistribución de clases:\")\n",
        "        unique, counts = np.unique(y, return_counts=True)\n",
        "        for clase, cantidad in zip(unique, counts):\n",
        "            print(f\"Clase {clase}: {cantidad} instancias\")\n",
        "\n",
        "        # División de datos\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Creacion de la  instancia de clasificadores\n",
        "\n",
        "        clasificadores = Clasificadores(X_train, y_train)\n",
        "\n",
        "        # Entrenar modelos con búsquda de hiperparámetros\n",
        "\n",
        "        clasificadores.entrenar_modelos()\n",
        "\n",
        "        # Evaluar modelos\n",
        "\n",
        "        clasificadores.evaluar_modelos(X_test, y_test)\n",
        "\n",
        "        # Realizar validación cruzada\n",
        "\n",
        "        clasificadores.cross_validation(X_train, y_train)\n",
        "\n",
        "        # Visualizar y comparar resultados\n",
        "\n",
        "        clasificadores.visualizar_resultados()\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Por favor, asegúrate de tener un archivo \\\n",
        "        'cancer.csv' en el directorio correcto.\")\n",
        "    except DataLoadError as e:\n",
        "        print(f\"Error de carga de datos: {e}\")\n",
        "    except ModelTrainingError as e:\n",
        "        print(f\"Error de entrenamiento: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error inesperado: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrZ_6goqzCmS",
        "outputId": "8e22f6cc-3404-4893-ff7d-43e9815abf58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Información del Dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 499 entries, 0 to 498\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       499 non-null    int64  \n",
            " 1   diagnosis                499 non-null    object \n",
            " 2   radius_mean              499 non-null    float64\n",
            " 3   texture_mean             499 non-null    float64\n",
            " 4   perimeter_mean           499 non-null    float64\n",
            " 5   area_mean                499 non-null    float64\n",
            " 6   smoothness_mean          499 non-null    float64\n",
            " 7   compactness_mean         499 non-null    float64\n",
            " 8   concavity_mean           499 non-null    float64\n",
            " 9   concave points_mean      499 non-null    float64\n",
            " 10  symmetry_mean            499 non-null    float64\n",
            " 11  fractal_dimension_mean   499 non-null    float64\n",
            " 12  radius_se                499 non-null    float64\n",
            " 13  texture_se               499 non-null    float64\n",
            " 14  perimeter_se             499 non-null    float64\n",
            " 15  area_se                  499 non-null    float64\n",
            " 16  smoothness_se            499 non-null    float64\n",
            " 17  compactness_se           499 non-null    float64\n",
            " 18  concavity_se             499 non-null    float64\n",
            " 19  concave points_se        499 non-null    float64\n",
            " 20  symmetry_se              499 non-null    float64\n",
            " 21  fractal_dimension_se     499 non-null    float64\n",
            " 22  radius_worst             499 non-null    float64\n",
            " 23  texture_worst            499 non-null    float64\n",
            " 24  perimeter_worst          499 non-null    float64\n",
            " 25  area_worst               499 non-null    float64\n",
            " 26  smoothness_worst         499 non-null    float64\n",
            " 27  compactness_worst        499 non-null    float64\n",
            " 28  concavity_worst          499 non-null    float64\n",
            " 29  concave points_worst     499 non-null    float64\n",
            " 30  symmetry_worst           499 non-null    float64\n",
            " 31  fractal_dimension_worst  499 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 124.9+ KB\n",
            "None\n",
            "Error de carga de datos: Error preparando datos: \"['diagnosis'] not found in axis\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spQVdJgSzkug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}